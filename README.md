# Models Donâ€™t Get Partial Credit: An Analysis of Contradictory Evidence on Multi-hop Question Answering Chains of Reasoning

**Abstract**

While question answering (QA) models perform well in open-book settings, these
models can create false chains of reasoning in the presence of contradictory evi-
dence. In doing so, such models engage in a form of confirmation bias that may
be misleading or even harmful to an information-seeking agent. We analyze how
different forms of adversarial data affect multi-hop QA model reasoning, using
ALBERT, and find that QA systems are able to answer XX% of questions in this
environment. We introduce adversarial knowledge in the evidence sources and
propose a novel QA approach that includes evidential reasoning to answer ques-
tions while citing contradictory information as evidence as a means to measure
uncertainty. We validate this approach through a pilot user study to show the impact
of including positive and negative evidence on multi-hop QA using the HotPotQA
dataset.
