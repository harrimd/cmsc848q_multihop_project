# Models Donâ€™t Get Partial Credit: An Analysis of Contradictory Evidence on Multi-hop Question Answering Chains of Reasoning

**Abstract**

While question answering (QA) models perform well in open-book settings, these
models can create false chains of reasoning in the presence of contradictory evi-
dence. In doing so, such models engage in a form of confirmation bias that may
be misleading or even harmful to an information-seeking agent. We analyze how
different forms of adversarial data affect multi-hop QA model reasoning, using
ALBERT, and find that QA systems are able to answer XX% of questions in this
environment. We introduce adversarial knowledge in the evidence sources and
propose a novel QA approach that includes evidential reasoning to answer ques-
tions while citing contradictory information as evidence as a means to measure
uncertainty. We validate this approach through a pilot user study to show the impact
of including positive and negative evidence on multi-hop QA using the HotPotQA
dataset.

**Overleaf**

Full paper found here: https://www.overleaf.com/project/62422103bb675e542f71b335

**Project Info**

Project info, tasks, and related papers can be found here: https://docs.google.com/document/d/1-TW3Nn8XHNibmvQ_t2AIkMq-LOeSS5SAXxXKrSVLatc/edit
